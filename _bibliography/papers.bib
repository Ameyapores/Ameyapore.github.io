---
2023
---
@article{pore2023surgical,
  title={Surgical Subtask Automation for Intraluminal Procedures using Deep Reinforcement Learning},
  author={Pore, Ameya},
  year={2023},
  abbr={PhD Thesis},
  pdf={https://Ameyapores.github.io/assets/pdf/Pore2023thesis.pdf},
  html={https://iris.univr.it/handle/11562/1099166},
}

@article{pore2023autonomous,
  title={Autonomous Navigation for Robot-Assisted Intraluminal and Endovascular Procedures: A Systematic Review},
  author={Pore, Ameya and Li, Zhen and Dall'Alba, Diego and Hernansanz, Albert and De Momi, Elena and Menciassi, Arianna and Gelp{\'\i}, Alicia Casals and Dankelman, Jenny and Fiorini, Paolo and Vander Poorten, Emmanuel},
  journal={IEEE Transactions on Robotics},
  year={2023},
  publisher={IEEE},
  abbr={T-RO},
  selected={true},
  abstract={Increased demand for less invasive procedures has accelerated the adoption of Intraluminal Procedures (IP) and Endovascular Interventions (EI) performed through body lumens and vessels. As navigation through lumens and vessels is quite complex, interest grows to establish autonomous navigation techniques for IP and EI for reaching the target area. Current research efforts are directed toward increasing the Level of Autonomy (LoA) during the navigation phase. One key ingredient for autonomous navigation is Motion Planning (MP) techniques. This paper provides an overview of MP techniques categorizing them based on LoA. Our analysis investigates advances for the different clinical scenarios. Through a systematic literature analysis using the PRISMA method, the study summarizes relevant works and investigates the clinical aim, LoA, adopted MP techniques, and validation types. We identify the limitations of the corresponding MP methods and provide directions to improve the robustness of the algorithms in dynamic intraluminal environments. MP for IP and EI can be classified into four subgroups: node, sampling, optimization, and learning-based techniques, with a notable rise in learning-based approaches in recent years. One of the review's contributions is the identification of the limiting factors in IP and EI robotic systems hindering higher levels of autonomous navigation. In the future, navigation is bound to become more autonomous, placing the clinician in a supervisory position to improve control precision and reduce workload.},
  html={https://ieeexplore.ieee.org/abstract/document/10124062},
}

@inproceedings{corsi2023constrained,
  title={Constrained Reinforcement Learning and Formal Verification for Safe Colonoscopy Navigation},
  author={Corsi*, Davide and Marzari*, Luca and Pore*, Ameya and Farinelli, Alessandro and Casals, Alicia and  Fiorini, Paolo and Dall'Alba, Diego},
  booktitle={IEEE International Conference on Intelligent Robots and Systems},
  year={2023},
  abbr={IROS},
  pdf={https://arxiv.org/pdf/2303.03207.pdf},
  html={https://arxiv.org/abs/2303.03207},
  abstract={The field of robotic Flexible Endoscopes (FEs) has progressed significantly, offering a promising solution to reduce patient discomfort. However, the limited autonomy of most robotic FEs results in non-intuitive and challenging manoeuvres, constraining their application in clinical settings. While previous studies have employed lumen tracking for autonomous navigation, they fail to adapt to the presence of obstructions and sharp turns when the endoscope faces the colon wall. In this work, we propose a Deep Reinforcement Learning (DRL)-based navigation strategy that eliminates the need for lumen tracking. However, the use of DRL methods poses safety risks as they do not account for potential hazards associated with the actions taken. To ensure safety, we exploit a Constrained Reinforcement Learning (CRL) method to restrict the policy in a predefined safety regime. Moreover, we present a model selection strategy that utilises Formal Verification (FV) to choose a policy that is entirely safe before deployment. We validate our approach in a virtual colonoscopy environment and report that out of the 300 trained policies, we could identify three policies that are entirely safe. Our work demonstrates that CRL, combined with model selection through FV, can improve the robustness and safety of robotic behaviour in surgical applications.}
}

---
2022
---

@inproceedings{pore2022colonoscopy,
  title={Colonoscopy navigation using end-to-end deep visuomotor control: A user study},
  author={Pore, Ameya and Finocchiaro, Martina and Dall'Alba, Diego and Hernansanz, Albert and Ciuti, Gastone and Arezzo, Alberto and Menciassi, Arianna and Casals, Alicia and Fiorini, Paolo},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={9582--9588},
  year={2022},
  abbr={IROS},
  organization={IEEE},
  selected={true},
  abstract={Flexible Endoscopes (FEs) for colonoscopy present several limitations due to their inherent complexity, resulting in patient discomfort and lack of intuitiveness for clinicians. Robotic FEs with autonomous control represent a viable solution to reduce the workload of endoscopists and the training time while improving the procedure outcome. Prior works on autonomous endoscope FE control use heuristic policies that limit their generalisation to the unstructured and highly deformable colon environment and require frequent human intervention. This work proposes an image-based FE control using Deep Reinforcement Learning, called Deep Visuomotor Control (DVC), to exhibit adaptive behaviour in convoluted sections of the colon. DVC learns a mapping between the images and the FE control signal. A first user study of 20 expert gastrointestinal endoscopists was carried out to compare their navigation performance with DVC using a realistic virtual simulator. The results indicate that DVC shows equivalent performance on several assessment parameters, being more safer. Moreover, a second user study with 20 novice users was performed to demonstrate easier human supervision compared to a state-of-the-art heuristic control policy. Seamless supervision of colonoscopy procedures would enable endoscopists to focus on the medical decision rather than on the control of FE.},
  html={Colonoscopy navigation using end-to-end deep visuomotor control: A user study}
}

@techreport{pore2022endovine,
  title={EndoVine: Soft Robotic Endoscope for Colonoscopy},
  author={Pore, Ameya and Piccinelli, Nicola and De Rossi, Giacomo and Piano, Matteo and Meli, Daniele and Dall’Alba, Diego and Muradore, Riccardo and Fiorini, Paolo},
  year={2022},
  institution={EasyChair},
  abbr={HSMR},
  pdf={https://easychair.org/publications/preprint_download/tMdlr}
}

@inproceedings{herrera2022autonomous,
  title={Autonomous image guided control of endoscopic orientation for OCT scanning},
  author={Herrera, Jose Fernando Gonzalez and Pore, Ameya and Sestini, Luca and Sahu, Sujit Kumar and Liao, Guiqiu and Zanne, Philippe and Dall'Alba, Diego and Hernansanz, Albert and Rosa, Benoit and Nageotte, Florent and others},
  booktitle={CRAS, Naples, Italy, avril 2022},
  year={2022},
  abbr={CRAS},
  html={https://hal.science/hal-04027640/}
}

---
2021
---

@inproceedings{marzari2021towards,
  title={Towards hierarchical task decomposition using deep reinforcement learning for pick and place subtasks},
  author={Marzari, Luca and Pore, Ameya and Dall'Alba, Diego and Aragon-Camarasa, Gerardo and Farinelli, Alessandro and Fiorini, Paolo},
  booktitle={2021 20th International Conference on Advanced Robotics (ICAR)},
  pages={640--645},
  year={2021},
  abbr={ICAR},
  organization={IEEE},
  abstract={Deep Reinforcement Learning (DRL) is emerging as a promising approach to generate adaptive behaviors for robotic platforms. However, a major drawback of using DRL is the data-hungry training regime that requires millions of trial and error attempts, which is impractical when running experiments on robotic systems. Learning from Demonstrations (LfD) has been introduced to solve this issue by cloning the behavior of expert demonstrations. However, LfD requires a large number of demonstrations that are difficult to be acquired since dedicated complex setups are required. To overcome these limitations, we propose a multi-subtask reinforcement learning methodology where complex pick and place tasks can be decomposed into low-level subtasks. These subtasks are parametrized as expert networks and learned via DRL methods. Trained subtasks are then combined by a high-level choreographer to accomplish the intended pick and place task considering different initial configurations. As a testbed, we use a pick and place robotic simulator to demonstrate our methodology and show that our method outperforms a benchmark methodology based on LfD in terms of sample-efficiency. We transfer the learned policy to the real robotic system and demonstrate robust grasping using various geometric-shaped objects.},
  html={https://ieeexplore.ieee.org/abstract/document/9659344}
}



@inproceedings{pore2021learning,
  title={Learning from demonstrations for autonomous soft-tissue retraction},
  author={Pore, Ameya and Tagliabue, Eleonora and Piccinelli, Marco and Dall’Alba, Diego and Casals, Alicia and Fiorini, Paolo},
  booktitle={2021 International Symposium on Medical Robotics (ISMR)},
  pages={1--7},
  year={2021},
  abbr={ISMR},
  organization={IEEE},
  abstract={The current research focus in Robot-Assisted Minimally Invasive Surgery (RAMIS) is directed towards increasing the level of robot autonomy, to place surgeons in a supervisory position. Although Learning from Demonstrations (LfD) approaches are among the preferred ways for an autonomous surgical system to learn expert gestures, they require a high number of demonstrations and show poor generalization to the variable conditions of the surgical environment. In this work, we propose an LfD methodology based on Generative Adversarial Imitation Learning (GAIL) that is built on a Deep Reinforcement Learning (DRL) setting. GAIL combines generative adversarial networks to learn the distribution of expert trajectories with a DRL setting to ensure generalisation of trajectories providing human-like behaviour. We consider automation of tissue retraction, a common RAMIS task that involves soft tissues manipulation to expose a region of interest. In our proposed methodology, a small set of expert trajectories can be acquired through the da Vinci Research Kit (dVRK) and used to train the proposed LfD method inside a simulated environment. Results indicate that our methodology can accomplish the tissue retraction task with human-like behaviour while being more sample-efficient than the baseline DRL method. Towards the end, we show that the learnt policies can be successfully transferred to the real robotic platform and deployed for soft tissue retraction on a synthetic phantom.},
  html={https://ieeexplore.ieee.org/abstract/document/9661514}
}

@inproceedings{pore2021safe,
  title={Safe Reinforcement Learning Using Formal Verification for Tissue Retraction in Autonomous Robotic-Assisted Surgery},
  author={Pore*, Ameya and Corsi*, Davide and Marchesini*, Enrico and Dall'Alba, Diego and Casals, Alicia and Farinelli, Alessandro  and Fiorini, Paolo},
  booktitle={IEEE International Conference on Intelligent Robots and Systems},
  year={2021},
  abbr={IROS},
  selected={true},
  html={https://ieeexplore.ieee.org/abstract/document/9636175/},
  abstract={Deep Reinforcement Learning (DRL) is a viable solution for automating repetitive surgical subtasks due to its ability to learn complex behaviours in a dynamic environment. This task automation could lead to reduced surgeon’s cognitive workload, increased precision in critical aspects of the surgery, and fewer patient-related complications. However, current DRL methods do not guarantee any safety criteria as they maximise cumulative rewards without considering the risks associated with the actions performed. Due to this limitation, the application of DRL in the safety-critical paradigm of robot-assisted Minimally Invasive Surgery (MIS) has been constrained. In this work, we introduce a Safe-DRL framework that incorporates safety constraints for the automation of surgical subtasks via DRL training. We validate our approach in a virtual scene that replicates a tissue retraction task commonly occurring in multiple phases of an MIS. Furthermore, to evaluate the safe behaviour of the robotic arms, we formulate a formal verification tool for DRL methods that provides the probability of unsafe configurations. Our results indicate that a formal analysis guarantees safety with high confidence such that the robotic instruments operate within the safe workspace and avoid hazardous interaction with other anatomical structures.}
}

---
2021
---

}

@inproceedings{pitsillos2021intrinsic,
  title={Intrinsic Robotic Introspection: Learning Internal States From Neuron Activations},
  author={Pitsillos, Nikos and Pore, Ameya and Jensen, Bj{\o}rn Sand and Aragon-Camarasa, Gerardo},
  booktitle={2021 IEEE International Conference on Development and Learning (ICDL)},
  pages={1--7},
  year={2021},
  abbr={ICDL},
  organization={IEEE},
  abstract={We present an introspective framework inspired by the process of how humans perform introspection. Our working assumption is that neural network activations encode information, and building internal states from these activations can improve the performance of an actor-critic model. We perform experiments where we first train a Variational Autoencoder model to reconstruct the activations of a feature extraction network and use the latent space to improve the performance of an actor-critic when deciding which low-level robotic behaviour to execute. We show that internal states reduce the number of episodes needed by about 1300 episodes while training an actor-critic, denoting faster convergence to get a high success value while completing a robotic task.},
  html={https://ieeexplore.ieee.org/abstract/document/9515672}
}
---
2020
---

@inproceedings{tagliabue2020soft,
  title={Soft tissue simulation environment to learn manipulation tasks in autonomous robotic surgery},
  author={Tagliabue, Eleonora and Pore, Ameya and Dall’Alba, Diego and Magnabosco, Enrico and Piccinelli, Marco and Fiorini, Paolo},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3261--3266},
  year={2020},
  abbr={IROS},
  organization={IEEE},
  abstract={Reinforcement Learning (RL) methods have demonstrated promising results for the automation of subtasks in surgical robotic systems. Since many trial and error attempts are required to learn the optimal control policy, RL agent training can be performed in simulation and the learned behavior can be then deployed in real environments. In this work, we introduce an open-source simulation environment providing support for position based dynamics soft bodies simulation and state-of-the-art RL methods. We demonstrate the capabilities of the proposed framework by training an RL agent based on Proximal Policy Optimization in fat tissue manipulation for tumor exposure during a nephrectomy procedure. Leveraging on a preliminary optimization of the simulation parameters, we show that our agent is able to learn the task on a virtual replica of the anatomical environment. The learned behavior is robust to changes in the initial end-effector position. Furthermore, we show that the learned policy can be directly deployed on the da Vinci Research Kit, which is able to execute the trajectories generated by the RL agent. The proposed simulation environment represents an essential component for the development of next-generation robotic systems, where the interaction with the deformable anatomical environment is involved.},
  html={https://ieeexplore.ieee.org/abstract/document/9341710}
}


@inproceedings{pore2020framework,
  title={Framework for soft tissue manipulation and control using Deep Reinforcement Learning},
  author={Pore, Ameya and Tagliabue, Eleonora and Dall'Alba, Diego and Fiorini, Paolo and others},
  booktitle={Proceedings of the 10th Joint Workshop on New Technologies for Computer/Robot Assisted Surgery},
  pages={0--1},
  year={2020},
  abbr={CRAS},
  pdf={https://atlas-itn.eu/wp-content/uploads/2020/12/CRAS_2020_Amey.pdf}
}

@inproceedings{pore2020simple,
  title={On simple reactive neural networks for behaviour-based reinforcement learning},
  author={Pore, Ameya and Aragon-Camarasa, Gerardo},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7477--7483},
  year={2020},
  abbr={ICRA},
  organization={IEEE},
  abstract={We present a behaviour-based reinforcement learning approach, inspired by Brook's subsumption architecture, in which simple fully connected networks are trained as reactive behaviours. Our working assumption is that a pick and place robotic task can be simplified by leveraging domain knowledge of a robotics developer to decompose and train reactive behaviours; namely, approach, grasp, and retract. Then the robot autonomously learns how to combine reactive behaviours via an Actor-Critic architecture. We use an Actor-Critic policy to determine the activation and inhibition mechanisms of the reactive behaviours in a particular temporal sequence. We validate our approach in a simulated robot environment where the task is about picking a block and taking it to a target position while orienting the gripper from a top grasp. The latter represents an extra degree-of-freedom of which current end-to-end reinforcement learning approaches fail to generalise. Our findings suggest that robotic learning can be more effective if each behaviour is learnt in isolation and then combined them to accomplish the task. That is, our approach learns the pick and place task in 8,000 episodes, which represents a drastic reduction in the number of training episodes required by an end-to-end approach ( 95,000 episodes) and existing state-of-the-art algorithms.},
  html={https://ieeexplore.ieee.org/abstract/document/9197262}
}

